{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c1aff2",
   "metadata": {
    "id": "55c1aff2"
   },
   "source": [
    "## Prompt Engineering for Item Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b773af2",
   "metadata": {
    "id": "9b773af2"
   },
   "source": [
    "### Workshop Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c350a97",
   "metadata": {
    "id": "6c350a97"
   },
   "source": [
    "This hands-on workshop covers various prompt engineering techniques\n",
    "for generating high-quality items.\n",
    "\n",
    "Learning Objectives:\n",
    "- Master different types of prompting strategies\n",
    "- Implement structured prompt templates for item generation\n",
    "- Apply few-shot learning for consistent item quality\n",
    "- Use chain-of-thought reasoning for complex assessments\n",
    "- Implement evaluation and refinement workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc49e5c",
   "metadata": {
    "id": "4cc49e5c"
   },
   "source": [
    "### Basic Concept\n",
    "Prompt engineering is the process of crafting effective instructions for language models to get the best possible results. It means carefully choosing words, providing context, and structuring requests in ways that help LLMs produce more accurate, helpful, and on-target responses.\n",
    "\n",
    "In item development, prompt engineering ensures that generated items are educationally sound, technically accurate, appropriately challenging, and consistently aligned with learning objectives.\n",
    "\n",
    "#### Prompting Strategies\n",
    "Effective prompt engineering for item generation employs various strategic approaches, each designed to optimize specific aspects of LLM output.\n",
    "\n",
    "##### Zero-shot Prompting\n",
    "This is the simplest prompting strategy where we give the AI instructions\n",
    "without any examples. It's like asking someone to do a task by just\n",
    "explaining what you want, without showing them how others have done it.\n",
    "\n",
    "**When to use Zero-Shot:**\n",
    "1. Quick prototyping and testing\n",
    "2. Simple, straightforward tasks\n",
    "3. When you don't have good examples ready\n",
    "4. For creative tasks where you want variety\n",
    "\n",
    "**Limitations:**\n",
    "1. Less consistent formatting\n",
    "2. May misunderstand complex requirements\n",
    "3. Output quality can vary\n",
    "\n",
    "##### Few-shot Prompting\n",
    "Few-shot prompting is like teaching by showing examples. Instead of just\n",
    "telling the AI what to do, we show it a few examples of inputs and their\n",
    "desired outputs, and it learns the pattern.\n",
    "\n",
    "**When to use Few-Shot:**\n",
    "1. When you need consistent formatting\n",
    "2. When you have good examples available\n",
    "3. For complex tasks with specific patterns\n",
    "4. When zero-shot isn't giving consistent results\n",
    "\n",
    "**Benefits:**\n",
    "1. More consistent output format\n",
    "2. Better understanding of requirements\n",
    "3. Can encode domain expertise through examples\n",
    "4. Reduces ambiguity\n",
    "\n",
    "**Limitations:**\n",
    "1. Requires good quality examples\n",
    "2. Uses more tokens (costs more)\n",
    "3. Can overfit to example patterns\n",
    "\n",
    "##### Chain-of-Thought Prompting\n",
    "Chain-of-thought prompting guides the AI through explicit step-by-step reasoning processes, making the model's thinking visible and systematic. This approach is particularly valuable for complex assessment item development where multiple considerations must be balanced.\n",
    "\n",
    "**When to use Chain-of-Thought:**\n",
    "1. For complex assessment scenarios requiring multi-step analysis\n",
    "2. When generating items that test higher-order thinking skills\n",
    "3. For quality assurance and validation of item construction\n",
    "4. When transparency in the generation process is important\n",
    "5. For developing items with sophisticated distractors\n",
    "\n",
    "**Benefits:**\n",
    "1. Improved reasoning quality: Forces systematic consideration of all aspects\n",
    "2. Transparency: Makes the generation process auditable and reviewable\n",
    "3. Better distractor development: Explicit focus on misconception-based options\n",
    "4. Quality control: Each step can be evaluated independently\n",
    "\n",
    "**Limitations:**\n",
    "1. Longer prompts and responses cost more token usage\n",
    "2. May generate unnecessarily complex items\n",
    "3. More processing time required\n",
    "4. Requires careful prompt structure to maintain consistency\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363bc53",
   "metadata": {
    "id": "8363bc53"
   },
   "source": [
    "### Hands-on Setup\n",
    "We'll begin by loading the required libraries and configuring our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183ed6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langchain) (1.0.1)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Using cached langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.38)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\olumi\\onedrive - university of iowa\\research files\\ai-me con\\training\\training_files_10_26_25\\venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.1)\n",
      "Using cached langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Using cached langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Using cached langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "Successfully installed langchain-1.0.2 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9916c013",
   "metadata": {
    "id": "9916c013"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up Google API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e074f",
   "metadata": {
    "id": "215e074f"
   },
   "source": [
    "##### Zero-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa4dea8",
   "metadata": {
    "id": "ffa4dea8",
    "outputId": "8ae59726-1b94-4454-d862-486b7eea6268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASIC ZERO-SHOT EXAMPLE\n",
      "========================================\n",
      "Generating question about 'photosynthesis'...\n",
      "\n",
      "Generated Question:\n",
      "Here is a multiple-choice question about photosynthesis:\n",
      "\n",
      "**Question:** Which of the following correctly identifies the primary products of photosynthesis?\n",
      "\n",
      "A) Carbon dioxide and water\n",
      "B) Glucose (sugar) and oxygen\n",
      "C) Light energy and chlorophyll\n",
      "D) Nitrogen and water vapor\n",
      "\n",
      "**Correct Answer:** B\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here is a multiple-choice question about photosynthesis:\\n\\n**Question:** Which of the following correctly identifies the primary products of photosynthesis?\\n\\nA) Carbon dioxide and water\\nB) Glucose (sugar) and oxygen\\nC) Light energy and chlorophyll\\nD) Nitrogen and water vapor\\n\\n**Correct Answer:** B', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--6e22270e-73e7-4546-8258-f30581f1fb88-0', usage_metadata={'input_tokens': 31, 'output_tokens': 775, 'total_tokens': 806, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 713}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basic_zero_shot_example():\n",
    "    \"\"\"\n",
    "    The simplest form of zero-shot prompting using updated LangChain syntax\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"BASIC ZERO-SHOT EXAMPLE\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Create a simple prompt\n",
    "    prompt_text = (\n",
    "        \"Create a multiple-choice question about photosynthesis.\\n\"\n",
    "        \"Include 4 options (A, B, C, D) and indicate the correct answer.\\n\"\n",
    "    )\n",
    "\n",
    "    print(f\"Generating question about 'photosynthesis'...\\n\")\n",
    "\n",
    "    try:\n",
    "        result = llm.invoke(prompt_text)\n",
    "        print(f\"Generated Question:\")\n",
    "        print(result.content)\n",
    "        print(\"\\n\" + \"=\" * 40)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Call the function\n",
    "basic_zero_shot_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92030fd7",
   "metadata": {
    "id": "92030fd7"
   },
   "source": [
    "##### Few-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0f2bac",
   "metadata": {
    "id": "6c0f2bac"
   },
   "outputs": [],
   "source": [
    "# Mathematics Examples\n",
    "MATH_EXAMPLES = [\n",
    "    {\n",
    "        \"instruction\": \"Create a linear equation problem\",\n",
    "        \"grade\": \"8th Grade\",\n",
    "        \"topic\": \"Solving y - 3 = 12\",\n",
    "        \"output\": \"\"\"Question: Solve for y: y - 3 = 12\n",
    "A) y = 9\n",
    "B) y = 15\n",
    "C) y = 4\n",
    "D) y = 36\n",
    "Correct Answer: B\n",
    "Explanation: To solve y - 3 = 12, add 3 to both sides: y = 12 + 3 = 15\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Create a linear equation problem\",\n",
    "        \"grade\": \"8th Grade\",\n",
    "        \"topic\": \"Solving m + 8 = 20\",\n",
    "        \"output\": \"\"\"Question: Solve for m: m + 8 = 20\n",
    "A) m = 28\n",
    "B) m = 12\n",
    "C) m = 8\n",
    "D) m = 160\n",
    "Correct Answer: B\n",
    "Explanation: To solve m + 8 = 20, subtract 8 from both sides: m = 20 - 8 = 12\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Create a linear equation problem\",\n",
    "        \"grade\": \"8th Grade\",\n",
    "        \"topic\": \"Solving x + 7 = 15\",\n",
    "        \"output\": \"\"\"Question: Solve for x: x + 7 = 15\n",
    "A) x = 8\n",
    "B) x = 22\n",
    "C) x = 7\n",
    "D) x = 15\n",
    "Correct Answer: A\n",
    "Explanation: To solve x + 7 = 15, subtract 7 from both sides: x = 15 - 7 = 8\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Medical Examples\n",
    "MEDICAL_EXAMPLES = [\n",
    "    {\n",
    "        \"specialty\": \"Physician Assistant\",\n",
    "        \"topic\": \"Acute Coronary Syndrome\",\n",
    "        \"presentation\": \"58-year-old male with chest pain\",\n",
    "        \"output\": \"\"\"Question: A 58-year-old male presents with crushing chest pain radiating to his left arm for 2 hours. ECG shows ST-segment elevation in leads II, III, and aVF. What is the most likely diagnosis?\n",
    "A) Anterior STEMI\n",
    "B) Inferior STEMI\n",
    "C) Non-ST elevation MI\n",
    "D) Unstable angina\n",
    "Correct Answer: B\n",
    "Explanation: ST elevation in leads II, III, and aVF indicates an inferior wall STEMI.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"specialty\": \"Physician Assistant\",\n",
    "        \"topic\": \"Acute Coronary Syndrome\",\n",
    "        \"presentation\": \"62-year-old with chest pain and ECG changes\",\n",
    "        \"output\": \"\"\"Question: A 62-year-old man has chest pain with ECG showing ST depression in leads V4-V6. Initial troponin is normal. What classification best describes this presentation?\n",
    "A) STEMI\n",
    "B) NSTEMI\n",
    "C) Unstable angina\n",
    "D) Stable angina\n",
    "Correct Answer: C\n",
    "Explanation: ST depression with normal troponin suggests unstable angina. NSTEMI would have elevated troponin.\"\"\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8e175",
   "metadata": {
    "id": "a6e8e175"
   },
   "source": [
    "##### Few-shot with Mathematics Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc135ec",
   "metadata": {
    "id": "6fc135ec",
    "outputId": "d7e9714a-023c-4393-8662-acb372b2c761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEW-SHOT: MATHEMATICS LINEAR EQUATIONS\n",
      "Using these examples to teach the AI:\n",
      "\n",
      "Example 1:\n",
      "Input: Grade: 8th Grade, Topic: Solving y - 3 = 12\n",
      "Output: Question: Solve for y: y - 3 = 12\n",
      "A) y = 9\n",
      "B) y = 15\n",
      "C) y = 4\n",
      "D) y = 36\n",
      "Correct Answer: B\n",
      "Explanatio...\n",
      "\n",
      "Example 2:\n",
      "Input: Grade: 8th Grade, Topic: Solving m + 8 = 20\n",
      "Output: Question: Solve for m: m + 8 = 20\n",
      "A) m = 28\n",
      "B) m = 12\n",
      "C) m = 8\n",
      "D) m = 160\n",
      "Correct Answer: B\n",
      "Explanat...\n",
      "\n",
      "Now generating a new question...\n",
      "\n",
      "Generated Question:\n",
      "Question: Solve for n: n - 5 = 18\n",
      "A) n = 13\n",
      "B) n = 23\n",
      "C) n = 5\n",
      "D) n = 90\n",
      "Correct Answer: B\n",
      "Explanation: To solve n - 5 = 18, add 5 to both sides: n = 18 + 5 = 23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Question: Solve for n: n - 5 = 18\\nA) n = 13\\nB) n = 23\\nC) n = 5\\nD) n = 90\\nCorrect Answer: B\\nExplanation: To solve n - 5 = 18, add 5 to both sides: n = 18 + 5 = 23', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--9229a612-10ca-4e48-984d-5c2568189503-0', usage_metadata={'input_tokens': 248, 'output_tokens': 1005, 'total_tokens': 1253, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 922}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def few_shot_math_example():\n",
    "    \"\"\"\n",
    "    Few-shot for mathematics using examples\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"FEW-SHOT: MATHEMATICS LINEAR EQUATIONS\")\n",
    "\n",
    "    # Format examples for few-shot\n",
    "    examples = []\n",
    "    for ex in MATH_EXAMPLES[:2]:  # Use first 2 as examples\n",
    "        examples.append({\n",
    "            \"instruction\": f\"Grade: {ex['grade']}, Topic: {ex['topic']}\",\n",
    "            \"output\": ex['output']\n",
    "        })\n",
    "\n",
    "    # Show the examples we're using\n",
    "    print(f\"Using these examples to teach the AI:\")\n",
    "    for i, ex in enumerate(examples, 1):\n",
    "        print(f\"\\nExample {i}:\")\n",
    "        print(f\"Input: {ex['instruction']}\")\n",
    "        print(f\"Output: {ex['output'][:100]}...\")\n",
    "\n",
    "    # Create the prompts\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"instruction\", \"output\"],\n",
    "        template=\"Instruction: {instruction}\\n{output}\"\n",
    "    )\n",
    "\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=\"You are an expert at creating math assessment items. Follow these examples exactly:\",\n",
    "        suffix=\"Instruction: {instruction}\\n\",\n",
    "        input_variables=[\"instruction\"]\n",
    "    )\n",
    "\n",
    "    # Generate new question\n",
    "    chain = few_shot_prompt | llm\n",
    "\n",
    "    print(f\"\\nNow generating a new question...\\n\")\n",
    "\n",
    "    # Use invoke instead of run with proper parameter format\n",
    "    result = chain.invoke({\n",
    "        \"instruction\": \"Grade: 8th Grade, Topic: Solving n - 5 = 18\"\n",
    "    })\n",
    "\n",
    "    print(f\"Generated Question:\")\n",
    "    # Handle different response types\n",
    "    print(result.content if hasattr(result, 'content') else result)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Call the function (moved outside the function definition)\n",
    "few_shot_math_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e240e74",
   "metadata": {
    "id": "8e240e74"
   },
   "source": [
    "##### Chain-of -thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256a0dcd",
   "metadata": {
    "id": "256a0dcd",
    "outputId": "9be40ed5-0204-454d-e73c-ba3e9c825754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAIN-OF-THOUGHT: GRADE 8 MATHEMATICS\n",
      "==================================================\n",
      "Generating a chain-of-thought mathematics problem...\n",
      "\n",
      "CHAIN-OF-THOUGHT REASONING AND RESULT:\n",
      "==================================================\n",
      "Here's the step-by-step creation of the Grade 8 mathematics assessment item:\n",
      "\n",
      "---\n",
      "\n",
      "**Step 1 - Key concept analysis:**\n",
      "The question should test a student's ability to:\n",
      "1.  Formulate a linear equation from a real-world scenario.\n",
      "2.  Solve a multi-step linear equation with variables on both sides.\n",
      "3.  Use inverse operations to isolate the variable.\n",
      "4.  Correctly manage positive and negative integers during algebraic manipulation.\n",
      "5.  Interpret the solution in the context of the problem.\n",
      "\n",
      "**Step 2 - Grade level appropriateness:**\n",
      "This is appropriate for Grade 8 because common core standards (e.g., CCSS.MATH.CONTENT.8.EE.C.7.B) expect students to \"Solve linear equations with rational number coefficients, including equations whose solutions require expanding expressions using the distributive property and collecting like terms.\" This problem focuses on collecting like terms and variables on both sides, which is a core skill for this grade level. The numbers chosen are integers, avoiding complex fractions or decimals that might distract from the algebraic process.\n",
      "\n",
      "**Step 3 - Real-world context:**\n",
      "A common and relatable context for linear equations with variables on both sides is comparing the costs of two different services or plans, where each has a fixed fee and a variable rate. This naturally leads to an equation like `fixed_cost1 + rate1 * variable = fixed_cost2 + rate2 * variable`. I will choose a \"tutoring service\" comparison.\n",
      "\n",
      "**Step 4 - Problem scenario:**\n",
      "\"Two tutoring companies, Ace Tutors and Bright Minds, offer different pricing structures. Ace Tutors charges a one-time registration fee of $50 plus $20 per hour of tutoring. Bright Minds charges a one-time registration fee of $20 plus $25 per hour of tutoring.\"\n",
      "\n",
      "**Step 5 - Question stem:**\n",
      "\"For how many hours of tutoring will the total cost be the same for both companies?\"\n",
      "\n",
      "**Step 6 - Answer choices:**\n",
      "\n",
      "Let 'h' represent the number of hours of tutoring.\n",
      "Equation setup:\n",
      "Ace Tutors cost: $50 + 20h$\n",
      "Bright Minds cost: $20 + 25h$\n",
      "Set costs equal: $50 + 20h = 20 + 25h$\n",
      "\n",
      "**Solving for the correct answer:**\n",
      "$50 - 20 = 25h - 20h$\n",
      "$30 = 5h$\n",
      "$h = 6$\n",
      "\n",
      "A) **6 hours**\n",
      "    *   **Reasoning:** This is the correct solution derived by setting up the equation $50 + 20h = 20 + 25h$ and correctly isolating the variable 'h'.\n",
      "\n",
      "B) **14 hours**\n",
      "    *   **Common error:** A student might incorrectly move the constant term from one side by adding it to the other side instead of subtracting. For example, when moving the $20 from the right side to the left side, they might add $20 to $50, resulting in $70 + 20h = 25h$. Then, $70 = 5h$, leading to $h = 14$.\n",
      "\n",
      "C) **5 hours**\n",
      "    *   **Common error:** This could result from a simple arithmetic error in the final division step. After correctly reaching $30 = 5h$, a student might incorrectly calculate $30 \\div 5$ as $5$ instead of $6$ (e.g., confusing it with $25 \\div 5 = 5$ or $30 \\div 6 = 5$).\n",
      "\n",
      "D) **10 hours**\n",
      "    *   **Common error:** A student might incorrectly attempt to solve the problem by dividing one of the fixed fees by the difference in hourly rates. For instance, they might calculate the difference in hourly rates as $25 - 20 = 5$, and then divide the larger registration fee by this difference: $50 \\div 5 = 10$. This shows a misunderstanding of how to combine terms in a linear equation.\n",
      "\n",
      "---\n",
      "\n",
      "**Step 7 - Complete solution:**\n",
      "\n",
      "**Problem:**\n",
      "Two tutoring companies, Ace Tutors and Bright Minds, offer different pricing structures. Ace Tutors charges a one-time registration fee of $50 plus $20 per hour of tutoring. Bright Minds charges a one-time registration fee of $20 plus $25 per hour of tutoring. For how many hours of tutoring will the total cost be the same for both companies?\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "1.  **Define the variable:**\n",
      "    Let 'h' represent the number of hours of tutoring.\n",
      "\n",
      "2.  **Write expressions for the total cost for each company:**\n",
      "    *   Cost for Ace Tutors: $50 + 20h$\n",
      "    *   Cost for Bright Minds: $20 + 25h$\n",
      "\n",
      "3.  **Set up the equation:**\n",
      "    To find when the total costs are the same, set the two expressions equal to each other:\n",
      "    $50 + 20h = 20 + 25h$\n",
      "\n",
      "4.  **Solve the equation for 'h':**\n",
      "    *   **Step 1: Isolate the variable terms on one side.**\n",
      "        Subtract $20h$ from both sides of the equation:\n",
      "        $50 + 20h - 20h = 20 + 25h - 20h$\n",
      "        $50 = 20 + 5h$\n",
      "\n",
      "    *   **Step 2: Isolate the constant terms on the other side.**\n",
      "        Subtract $20$ from both sides of the equation:\n",
      "        $50 - 20 = 20 + 5h - 20$\n",
      "        $30 = 5h$\n",
      "\n",
      "    *   **Step 3: Solve for 'h'.**\n",
      "        Divide both sides by $5$:\n",
      "        $\\frac{30}{5} = \\frac{5h}{5}$\n",
      "        $h = 6$\n",
      "\n",
      "5.  **State the answer in context:**\n",
      "    The total cost will be the same for both companies after **6 hours** of tutoring.\n",
      "\n",
      "**Check (Optional):**\n",
      "*   Ace Tutors: $50 + 20(6) = 50 + 120 = $170\n",
      "*   Bright Minds: $20 + 25(6) = 20 + 150 = $170\n",
      "Since the costs are equal, the solution is correct.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here\\'s the step-by-step creation of the Grade 8 mathematics assessment item:\\n\\n---\\n\\n**Step 1 - Key concept analysis:**\\nThe question should test a student\\'s ability to:\\n1.  Formulate a linear equation from a real-world scenario.\\n2.  Solve a multi-step linear equation with variables on both sides.\\n3.  Use inverse operations to isolate the variable.\\n4.  Correctly manage positive and negative integers during algebraic manipulation.\\n5.  Interpret the solution in the context of the problem.\\n\\n**Step 2 - Grade level appropriateness:**\\nThis is appropriate for Grade 8 because common core standards (e.g., CCSS.MATH.CONTENT.8.EE.C.7.B) expect students to \"Solve linear equations with rational number coefficients, including equations whose solutions require expanding expressions using the distributive property and collecting like terms.\" This problem focuses on collecting like terms and variables on both sides, which is a core skill for this grade level. The numbers chosen are integers, avoiding complex fractions or decimals that might distract from the algebraic process.\\n\\n**Step 3 - Real-world context:**\\nA common and relatable context for linear equations with variables on both sides is comparing the costs of two different services or plans, where each has a fixed fee and a variable rate. This naturally leads to an equation like `fixed_cost1 + rate1 * variable = fixed_cost2 + rate2 * variable`. I will choose a \"tutoring service\" comparison.\\n\\n**Step 4 - Problem scenario:**\\n\"Two tutoring companies, Ace Tutors and Bright Minds, offer different pricing structures. Ace Tutors charges a one-time registration fee of $50 plus $20 per hour of tutoring. Bright Minds charges a one-time registration fee of $20 plus $25 per hour of tutoring.\"\\n\\n**Step 5 - Question stem:**\\n\"For how many hours of tutoring will the total cost be the same for both companies?\"\\n\\n**Step 6 - Answer choices:**\\n\\nLet \\'h\\' represent the number of hours of tutoring.\\nEquation setup:\\nAce Tutors cost: $50 + 20h$\\nBright Minds cost: $20 + 25h$\\nSet costs equal: $50 + 20h = 20 + 25h$\\n\\n**Solving for the correct answer:**\\n$50 - 20 = 25h - 20h$\\n$30 = 5h$\\n$h = 6$\\n\\nA) **6 hours**\\n    *   **Reasoning:** This is the correct solution derived by setting up the equation $50 + 20h = 20 + 25h$ and correctly isolating the variable \\'h\\'.\\n\\nB) **14 hours**\\n    *   **Common error:** A student might incorrectly move the constant term from one side by adding it to the other side instead of subtracting. For example, when moving the $20 from the right side to the left side, they might add $20 to $50, resulting in $70 + 20h = 25h$. Then, $70 = 5h$, leading to $h = 14$.\\n\\nC) **5 hours**\\n    *   **Common error:** This could result from a simple arithmetic error in the final division step. After correctly reaching $30 = 5h$, a student might incorrectly calculate $30 \\\\div 5$ as $5$ instead of $6$ (e.g., confusing it with $25 \\\\div 5 = 5$ or $30 \\\\div 6 = 5$).\\n\\nD) **10 hours**\\n    *   **Common error:** A student might incorrectly attempt to solve the problem by dividing one of the fixed fees by the difference in hourly rates. For instance, they might calculate the difference in hourly rates as $25 - 20 = 5$, and then divide the larger registration fee by this difference: $50 \\\\div 5 = 10$. This shows a misunderstanding of how to combine terms in a linear equation.\\n\\n---\\n\\n**Step 7 - Complete solution:**\\n\\n**Problem:**\\nTwo tutoring companies, Ace Tutors and Bright Minds, offer different pricing structures. Ace Tutors charges a one-time registration fee of $50 plus $20 per hour of tutoring. Bright Minds charges a one-time registration fee of $20 plus $25 per hour of tutoring. For how many hours of tutoring will the total cost be the same for both companies?\\n\\n**Solution:**\\n\\n1.  **Define the variable:**\\n    Let \\'h\\' represent the number of hours of tutoring.\\n\\n2.  **Write expressions for the total cost for each company:**\\n    *   Cost for Ace Tutors: $50 + 20h$\\n    *   Cost for Bright Minds: $20 + 25h$\\n\\n3.  **Set up the equation:**\\n    To find when the total costs are the same, set the two expressions equal to each other:\\n    $50 + 20h = 20 + 25h$\\n\\n4.  **Solve the equation for \\'h\\':**\\n    *   **Step 1: Isolate the variable terms on one side.**\\n        Subtract $20h$ from both sides of the equation:\\n        $50 + 20h - 20h = 20 + 25h - 20h$\\n        $50 = 20 + 5h$\\n\\n    *   **Step 2: Isolate the constant terms on the other side.**\\n        Subtract $20$ from both sides of the equation:\\n        $50 - 20 = 20 + 5h - 20$\\n        $30 = 5h$\\n\\n    *   **Step 3: Solve for \\'h\\'.**\\n        Divide both sides by $5$:\\n        $\\\\frac{30}{5} = \\\\frac{5h}{5}$\\n        $h = 6$\\n\\n5.  **State the answer in context:**\\n    The total cost will be the same for both companies after **6 hours** of tutoring.\\n\\n**Check (Optional):**\\n*   Ace Tutors: $50 + 20(6) = 50 + 120 = $170\\n*   Bright Minds: $20 + 25(6) = 20 + 150 = $170\\nSince the costs are equal, the solution is correct.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--1f7e7fbd-281c-4fe7-bf5c-182602cdf9cd-0', usage_metadata={'input_tokens': 317, 'output_tokens': 5157, 'total_tokens': 5474, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 3731}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chain_of_thought_math_example():\n",
    "    \"\"\"\n",
    "    Chain-of-thought prompting for Grade 8 mathematics\n",
    "    This shows the AI's step-by-step reasoning process\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"CHAIN-OF-THOUGHT: GRADE 8 MATHEMATICS\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Create a chain-of-thought prompt that guides step-by-step reasoning\n",
    "    cot_prompt = PromptTemplate(\n",
    "        input_variables=[\"grade\", \"topic\", \"concept\"],\n",
    "        template=\"\"\"\n",
    "You are creating a Grade {grade} mathematics assessment item about {topic}.\n",
    "\n",
    "Think through this step-by-step:\n",
    "\n",
    "Step 1: Identify the key mathematical concept\n",
    "What specific aspect of {concept} should this question test?\n",
    "\n",
    "Step 2: Determine appropriate difficulty level\n",
    "What makes this appropriate for Grade {grade} students?\n",
    "\n",
    "Step 3: Choose a real-world context\n",
    "What everyday situation would make this concept meaningful?\n",
    "\n",
    "Step 4: Design the problem scenario\n",
    "Create a clear, engaging problem setup.\n",
    "\n",
    "Step 5: Write the question stem\n",
    "Make it specific and unambiguous.\n",
    "\n",
    "Step 6: Develop answer choices\n",
    "- Create one correct answer using proper mathematical reasoning\n",
    "- Design three distractors based on common student errors\n",
    "\n",
    "Step 7: Provide complete solution\n",
    "Show the mathematical steps and reasoning.\n",
    "\n",
    "Now work through each step:\n",
    "\n",
    "Step 1 - Key concept analysis:\n",
    "[Analyze what to test]\n",
    "\n",
    "Step 2 - Grade level appropriateness:\n",
    "[Justify difficulty level]\n",
    "\n",
    "Step 3 - Real-world context:\n",
    "[Choose meaningful scenario]\n",
    "\n",
    "Step 4 - Problem scenario:\n",
    "[Create the setup]\n",
    "\n",
    "Step 5 - Question stem:\n",
    "[Write the question]\n",
    "\n",
    "Step 6 - Answer choices:\n",
    "A) [Correct answer with reasoning]\n",
    "B) [Common error: show what mistake leads here]\n",
    "C) [Common error: show what mistake leads here]\n",
    "D) [Common error: show what mistake leads here]\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create the chain\n",
    "    chain = cot_prompt | llm\n",
    "\n",
    "    print(\"Generating a chain-of-thought mathematics problem...\\n\")\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"grade\": \"8\",\n",
    "            \"topic\": \"Linear Equations\",\n",
    "            \"concept\": \"solving multi-step equations with variables on both sides\"\n",
    "        })\n",
    "\n",
    "        print(\"CHAIN-OF-THOUGHT REASONING AND RESULT:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(result.content if hasattr(result, 'content') else result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Call the function\n",
    "chain_of_thought_math_example()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
